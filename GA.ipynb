{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "import os\n",
    "import shap\n",
    "import re, pip, conda\n",
    "import seaborn as sns # 用于特征重要性柱状图 Seaborn默认的图形样式和调色板使得绘图更美观，无需手动调整样式\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve # 使用 roc_curve 函数计算 ROC 曲线的 FPR 和 TPR，并将这些数据存储为 pandas DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from ngboost import NGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, make_scorer\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置全局随机种子\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "data1 = pd.read_excel(r'D:\\Users\\刘洋\\Desktop\\测试负2.xlsx')\n",
    "X = data1.iloc[:, 1:12].values  # 取除最后一列之外的所有列作为特征\n",
    "y = data1.iloc[:, 12].values   # 最后一列为标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义评分标准\n",
    "scoring = {\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 定义遗传算法的适应度和个体\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# 注册生成 0 到 1 之间的随机浮点数，确保在合理范围内\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", random.uniform, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n=8)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义变异函数，确保不生成 complex 类型的值\n",
    "def custom_mutate(individual, indpb=0.2):\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < indpb:\n",
    "            mutation = random.uniform(-0.1, 0.1)  # 设置一个小范围的随机变异\n",
    "            individual[i] += mutation\n",
    "            individual[i] = max(0, min(individual[i], 1))  # 确保值在 [0, 1] 范围内\n",
    "    return individual,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 遗传算法参数设置\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "toolbox.register(\"mutate\", custom_mutate)  # 使用自定义变异函数\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 评估函数定义（针对各个模型）\n",
    "def evaluate_xgboost(individual):\n",
    "    model = XGBClassifier(\n",
    "        max_depth=int(max(min(individual[0] * 7 + 3, 10), 3)),\n",
    "        learning_rate=max(min(individual[1] * 0.29 + 0.01, 0.3), 0.01),\n",
    "        n_estimators = int(max(min(individual[2] * 250 + 50, 300), 50)),\n",
    "        subsample=max(min(individual[3] * 0.5 + 0.5, 1.0), 0.5),\n",
    "        reg_lambda=max(individual[4] * 10, 0),\n",
    "        gamma = max(individual[5] * 5, 0),\n",
    "        min_child_weight=int(max(min(individual[6] * 9 + 1, 10), 1)),\n",
    "        colsample_bytree=max(min(individual[7] * 0.5 + 0.5, 1.0), 0.5),\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42  # 保持一致性\n",
    "    )\n",
    "    scores = cross_validate(model, X_train, y_train, cv=3, scoring='roc_auc')['test_score']\n",
    "    return (scores.mean(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lightgbm(individual):\n",
    "   \n",
    "    model = LGBMClassifier(\n",
    "        max_depth = int(max(min(individual[0] * 5 + 3, 8), 3)),\n",
    "       \n",
    "        learning_rate=max(min(individual[1] * 0.29 + 0.01, 0.3), 0.01),\n",
    "        n_estimators=int(max(min(individual[2] * 250 + 50, 300), 50)),\n",
    "        subsample=max(min(individual[3] * 0.5 + 0.5, 1.0), 0.5),\n",
    "        \n",
    "        reg_lambda=max(individual[4] * 10, 0),\n",
    "        min_child_samples=int(max(min(individual[6] * 45 + 5, 50), 5)),\n",
    "        colsample_bytree=max(min(individual[7] * 0.5 + 0.5, 1.0), 0.5),\n",
    "        reg_alpha=max(individual[5] * 10, 0),\n",
    "        random_state=42  # 保持一致性\n",
    "    )\n",
    "    scores = cross_validate(model, X_train, y_train, cv=4, scoring='roc_auc')['test_score']\n",
    "    return (scores.mean(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_catboost(individual):\n",
    "    model = CatBoostClassifier(\n",
    "        depth=int(max(min(individual[0] * 14 + 1, 15), 1)),\n",
    "        learning_rate=max(min(individual[1] * 0.09 + 0.01, 0.1), 0.01),\n",
    "        iterations=int(max(min(individual[2] * 450 + 50, 500), 50)),\n",
    "        od_wait=int(max(min(individual[3] * 90 + 10, 100), 10)),\n",
    "        l2_leaf_reg=(max(min(individual[5] * 9 + 1, 10),1)),\n",
    "        bagging_temperature=max(individual[6] * 1, 0),\n",
    "        colsample_bylevel=max(min(individual[7] * 0.5 + 0.5, 1.0), 0.5),\n",
    "        verbose=0,\n",
    "        random_state=42  # 保持一致性\n",
    "    )\n",
    "    scores = cross_validate(model, X_train, y_train, cv=2, scoring='roc_auc')['test_score']\n",
    "    return (scores.mean(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ngboost(individual):\n",
    "    model = NGBClassifier(\n",
    "        n_estimators=int(max(min(individual[2] * 250 + 50, 300), 50)),\n",
    "        learning_rate=max(min(individual[1] * 0.09 + 0.01, 0.1), 0.01),\n",
    "        minibatch_frac=max(min(individual[3] * 0.3 + 0.7, 1.0), 0.7),\n",
    "        natural_gradient=bool(round(individual[6])),\n",
    "        random_state=42  # 保持一致性\n",
    "    )\n",
    "    scores = cross_validate(model, X_train, y_train, cv=3, scoring='roc_auc')['test_score']\n",
    "    return (scores.mean(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用遗传算法优化模型超参数\n",
    "def optimize_with_ga(evaluate_func, model_name):\n",
    "    toolbox.register(\"evaluate\", evaluate_func)\n",
    "    population = toolbox.population(n=20)    #种群规模\n",
    "    ngen = 40  # 迭代次数\n",
    "    cxpb = 0.5  # 交叉概率\n",
    "    mutpb = 0.2  # 变异概率\n",
    "\n",
    "    algorithms.eaSimple(population, toolbox, cxpb=cxpb, mutpb=mutpb, ngen=ngen,\n",
    "                         stats=None, halloffame=None, verbose=False\n",
    "                         )\n",
    "    best_individual = tools.selBest(population, k=1)[0]\n",
    "     # 将最佳个体转换为模型的实际参数字典\n",
    "    if model_name == \"XGBoost\":\n",
    "        optimal_params = {\n",
    "            'max_depth': int(max(min(best_individual[0] * 7 + 3, 10), 3)),\n",
    "            'learning_rate': max(min(best_individual[1] * 0.29 + 0.01, 0.3), 0.01),\n",
    "            'n_estimators': int(max(min(best_individual[2] * 250 + 50, 300), 50)),\n",
    "            'subsample': max(min(best_individual[3] * 0.5 + 0.5, 1.0), 0.5),\n",
    "            'reg_lambda': max(best_individual[4] * 10, 0),\n",
    "            'gamma': max(best_individual[5] * 5, 0),\n",
    "            'min_child_weight': int(max(min(best_individual[6] * 9 + 1, 10), 1)),\n",
    "            'colsample_bytree': max(min(best_individual[7] * 0.5 + 0.5, 1.0), 0.5)\n",
    "        }\n",
    "    elif model_name == \"LGBM\":\n",
    "        optimal_params = {\n",
    "            'max_depth': int(max(min(best_individual[0] * 5 + 3, 8), 3)),\n",
    "            'learning_rate': max(min(best_individual[1] * 0.29 + 0.01, 0.3), 0.01),\n",
    "            'n_estimators': int(max(min(best_individual[2] * 250 + 50, 300), 50)),\n",
    "            'subsample': max(min(best_individual[3] * 0.5 + 0.5, 1.0), 0.5),\n",
    "            'reg_lambda': max(best_individual[4] * 10, 0),\n",
    "            'min_child_samples': int(max(min(best_individual[6] * 45 + 5, 50), 5)),\n",
    "            'colsample_bytree': max(min(best_individual[7] * 0.5 + 0.5, 1.0), 0.5),\n",
    "            'reg_alpha': max(best_individual[5] * 10, 0)\n",
    "        }\n",
    "    elif model_name == \"CatBoost\":\n",
    "        optimal_params = {\n",
    "            'depth': int(max(min(best_individual[0] * 14 + 1, 15), 1)),\n",
    "            'learning_rate': max(min(best_individual[1] * 0.09 + 0.01, 0.1), 0.01),\n",
    "            'iterations': int(max(min(best_individual[2] * 450 + 50, 500), 50)),\n",
    "            'od_wait': int(max(min(best_individual[3] * 90 + 10, 100), 10)),\n",
    "            'l2_leaf_reg': max(min(best_individual[4] * 9 + 1, 10), 1),\n",
    "            'bagging_temperature': max(best_individual[5] * 1, 0),\n",
    "            'colsample_bylevel': max(min(best_individual[6] * 0.5 + 0.5, 1.0), 0.5)\n",
    "        }\n",
    "    elif model_name == \"NGBoost\":\n",
    "        optimal_params = {\n",
    "            'n_estimators': int(max(min(best_individual[2] * 250 + 50, 300), 50)),\n",
    "            'learning_rate': max(min(best_individual[1] * 0.09 + 0.01, 0.1), 0.01),\n",
    "            'minibatch_frac': max(min(best_individual[3] * 0.3 + 0.7, 1.0), 0.7),\n",
    "            'natural_gradient': bool(round(best_individual[6]))\n",
    "        }\n",
    "    \n",
    "    print(f\"Optimal Parameters for {model_name}: {optimal_params}\")\n",
    "    return optimal_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 获取并打印每个模型的最优参数\n",
    "optimal_params = {\n",
    "    \"XGBoost\": optimize_with_ga(evaluate_xgboost, \"XGBoost\"),\n",
    "    \"LGBM\": optimize_with_ga(evaluate_lightgbm, \"LGBM\"),\n",
    "    \"CatBoost\": optimize_with_ga(evaluate_catboost, \"CatBoost\"),\n",
    "    \"NGBoost\": optimize_with_ga(evaluate_ngboost, \"NGBoost\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal hyperparameters have been saved to D:\\Users\\刘洋\\Desktop\\GA最优参数4.xlsx\n"
     ]
    }
   ],
   "source": [
    "# %% 将最优参数保存到 Excel 文件\n",
    "output_file_path = r\"D:\\Users\\刘洋\\Desktop\\GA最优参数4.xlsx\"\n",
    "data = {'Model': [], 'Parameter': [], 'Value': []}\n",
    "\n",
    "# 遍历 optimal_params 字典，将参数数据添加到 data 字典中\n",
    "for model_name, params in optimal_params.items():\n",
    "    for param_name, param_value in params.items():\n",
    "        data['Model'].append(model_name)\n",
    "        data['Parameter'].append(param_name)\n",
    "        data['Value'].append(round(param_value, 3) if isinstance(param_value, float) else param_value)\n",
    "\n",
    "# 转换为 DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 保存到 Excel 文件\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    df.to_excel(writer, index=False, sheet_name='Optimal Hyperparameters')\n",
    "\n",
    "print(\"Optimal hyperparameters have been saved to\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 使用最优参数初始化模型\n",
    "models = {\n",
    "    \"XGBoost\": XGBClassifier(**optimal_params[\"XGBoost\"], use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    \"LGBM\": LGBMClassifier(**optimal_params[\"LGBM\"], random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(**optimal_params[\"CatBoost\"], random_seed=42, verbose=0),\n",
    "    \"NGBoost\": NGBClassifier(**optimal_params[\"NGBoost\"], random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估函数\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, cv):\n",
    "    result = cross_validate(model, X_train, y_train, cv=cv, scoring=scoring\n",
    "                            , return_train_score=True\n",
    "                            , verbose=False\n",
    "                            )\n",
    "    metrics = {\n",
    "        \"train\": {\n",
    "            \"RCO-AUC\": result['train_roc_auc'].mean(),\n",
    "            \"ACC\": result['train_accuracy'].mean(),\n",
    "            \"F1\": result['train_f1'].mean(),\n",
    "            \"Precision\": result['train_precision'].mean(),\n",
    "            \"Recall\": result['train_recall'].mean()\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"RCO-AUC\": roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]),\n",
    "            \"ACC\": accuracy_score(y_test, model.predict(X_test)),\n",
    "            \"F1\": f1_score(y_test, model.predict(X_test)),\n",
    "            \"Precision\": precision_score(y_test, model.predict(X_test)),\n",
    "            \"Recall\": recall_score(y_test, model.predict(X_test))\n",
    "        }\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉验证并评估优化后的模型\n",
    "results = {}\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1412)\n",
    "for name, model in models.items():\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    metrics = evaluate_model(model, X_train, y_train, X_test, y_test, cv)\n",
    "    end = time.time() - start\n",
    "    metrics[\"time\"] = end\n",
    "    results[name] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBoost\n",
      "Training time: 0.425 s\n",
      "Train scores:\n",
      "  RCO-AUC: 0.894\n",
      "  ACC: 0.803\n",
      "  F1: 0.815\n",
      "  Precision: 0.751\n",
      "  Recall: 0.890\n",
      "Test scores:\n",
      "  RCO-AUC: 0.872\n",
      "  ACC: 0.837\n",
      "  F1: 0.863\n",
      "  Precision: 0.815\n",
      "  Recall: 0.917\n",
      "\n",
      "Model: LGBM\n",
      "Training time: 0.249 s\n",
      "Train scores:\n",
      "  RCO-AUC: 0.870\n",
      "  ACC: 0.799\n",
      "  F1: 0.811\n",
      "  Precision: 0.745\n",
      "  Recall: 0.890\n",
      "Test scores:\n",
      "  RCO-AUC: 0.854\n",
      "  ACC: 0.837\n",
      "  F1: 0.863\n",
      "  Precision: 0.815\n",
      "  Recall: 0.917\n",
      "\n",
      "Model: CatBoost\n",
      "Training time: 45.652 s\n",
      "Train scores:\n",
      "  RCO-AUC: 1.000\n",
      "  ACC: 0.995\n",
      "  F1: 0.995\n",
      "  Precision: 1.000\n",
      "  Recall: 0.989\n",
      "Test scores:\n",
      "  RCO-AUC: 0.910\n",
      "  ACC: 0.860\n",
      "  F1: 0.880\n",
      "  Precision: 0.846\n",
      "  Recall: 0.917\n",
      "\n",
      "Model: NGBoost\n",
      "Training time: 1.861 s\n",
      "Train scores:\n",
      "  RCO-AUC: nan\n",
      "  ACC: 1.000\n",
      "  F1: 1.000\n",
      "  Precision: 1.000\n",
      "  Recall: 1.000\n",
      "Test scores:\n",
      "  RCO-AUC: 0.884\n",
      "  ACC: 0.837\n",
      "  F1: 0.857\n",
      "  Precision: 0.840\n",
      "  Recall: 0.875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 打印结果\n",
    "for name, metrics in results.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Training time: {metrics['time']:.3f} s\")\n",
    "    for phase in [\"train\", \"test\"]:\n",
    "        print(f\"{phase.capitalize()} scores:\")\n",
    "        for metric, score in metrics[phase].items():\n",
    "            print(f\"  {metric}: {score:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to D:\\Users\\刘洋\\Desktop\\GA精度4.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 将结果保存到指定位置的表格中\n",
    "rows = []\n",
    "for name, metrics in results.items():\n",
    "    for phase in [\"train\", \"test\"]:\n",
    "        row = {\n",
    "            'Model': name,\n",
    "            'Phase': phase,\n",
    "            'Training Time (s)': metrics['time'] if phase == 'train' else None\n",
    "        }\n",
    "        for metric, score in metrics[phase].items():\n",
    "            row[metric] = score\n",
    "        rows.append(row)\n",
    "\n",
    "# 创建 DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# 保存到 Excel 文件\n",
    "output_path = r'D:\\Users\\刘洋\\Desktop\\GA精度4.xlsx'\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Results have been saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "# 绘制所有模型的ROC曲线\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'GA-{name} (AUC = {roc_auc_score(y_test, y_pred_proba):.3f})')\n",
    "\n",
    "# 添加图例和图形的标签\n",
    "plt.plot([0, 1], [0, 1], 'k--',linewidth=1)  # 参考线：随机分类器的ROC曲线\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for All Models')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.savefig(r'D:\\Users\\刘洋\\Desktop\\GA_ROC4.png')\n",
    "plt.close()  # 关闭图像以确保保存后不会影响后续图形的显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取研究区数据\n",
    "all_data = pd.read_excel(r'D:\\Users\\刘洋\\Desktop\\无坐标 - 副本.xlsx')\n",
    "X_all = all_data.iloc[:, 1:12].values  # 第2到12列为特征值，共计11列\n",
    "\n",
    "# 数据标准化\n",
    "scaler_all = StandardScaler()\n",
    "X_all = scaler_all.fit_transform(X_all)\n",
    "\n",
    "# 初始化用于保存所有模型预测概率的 DataFrame\n",
    "probabilities_df = pd.DataFrame(index=all_data.index)\n",
    "\n",
    "# 对研究区数据进行概率预测\n",
    "for name, model in models.items():\n",
    "    # 使用之前训练好的模型对研究区数据进行预测\n",
    "    try:\n",
    "        y_prob_all = model.predict_proba(X_all)[:, 1]  # 获取研究区数据属于“正例”（滑坡易发）的概率\n",
    "    except AttributeError:\n",
    "        # 如果模型未训练，进行训练（使用训练集数据）\n",
    "        data1 = pd.read_excel(r'D:\\Users\\刘洋\\Desktop\\测试负2.xlsx', index_col=0)\n",
    "        X = data1.iloc[:, 0:-1].values  # 取除最后一列之外的所有列作为特征\n",
    "        y = data1.iloc[:, -1].values  # 最后一列为标签\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_prob_all = model.predict_proba(X_all)[:, 1]\n",
    "    \n",
    "    # 将预测概率添加到 DataFrame 中\n",
    "    probabilities_df[name] = y_prob_all\n",
    "    \n",
    "    # 绘制研究区数据的概率分布\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(y_prob_all, kde=True, bins=30)\n",
    "    plt.title(f'Probability Distribution for Landslide Susceptibility - {name}')\n",
    "    plt.xlabel('Predicted Probability of Landslide Susceptibility')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    # 输出概率预测的基本统计信息\n",
    "    print(f\"Probability Statistics for {name} Model:\")\n",
    "    print(f\"  Mean: {np.mean(y_prob_all):.3f}\")\n",
    "    print(f\"  Standard Deviation: {np.std(y_prob_all):.3f}\")\n",
    "    print(f\"  Min: {np.min(y_prob_all):.3f}\")\n",
    "    print(f\"  Max: {np.max(y_prob_all):.3f}\")\n",
    "    print()\n",
    "\n",
    "# 将所有模型的概率预测结果输出到 Excel 文件\n",
    "output_path = r'D:\\Users\\刘洋\\Desktop\\GA预测4.csv'\n",
    "probabilities_df.to_csv(output_path)\n",
    "print(f\"Combined probability predictions have been saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% SHAP 解释   英文文章的\n",
    "# 确保特征名称正确\n",
    "feature_names = all_data.columns[1:12]  # 第2到12列为特征名称\n",
    "\n",
    "# 对每个模型进行 SHAP 解释\n",
    "for name, model in models.items():\n",
    "    print(f\"Generating SHAP explanations for model: {name}\")\n",
    "    \n",
    "    # 使用 TreeExplainer 对树模型（XGBoost、LGBM、CatBoost）进行解释\n",
    "    if name in [\"XGBoost\", \"LGBM\", \"CatBoost\"]:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_all)\n",
    "\n",
    "        # 绘制 SHAP 总结图（柱状图）\n",
    "        shap.summary_plot(shap_values, X_all, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "        plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\SHAP_Summary_{name}_AllData.png')\n",
    "        plt.close()\n",
    "\n",
    "        # 绘制 SHAP 散点图（按特征显示的散点图）\n",
    "        if isinstance(shap_values, list):  # 检查是否有多个类别\n",
    "            for i in range(len(shap_values)):\n",
    "                shap.summary_plot(shap_values[i], X_all, feature_names=feature_names, plot_type=\"dot\", show=False)\n",
    "                plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\SHAP_Scatter_{name}_AllData_class_{i}.png')\n",
    "                plt.close()\n",
    "        else:\n",
    "            shap.summary_plot(shap_values, X_all, feature_names=feature_names, plot_type=\"dot\", show=False)\n",
    "            plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\SHAP_Scatter_{name}_AllData.png')\n",
    "            plt.close()\n",
    "\n",
    "    # 使用通用的 SHAP Explainer 进行解释 (NGBoost)\n",
    "    elif name == \"NGBoost\":\n",
    "        explainer = shap.Explainer(model.predict, X_all)\n",
    "        shap_values = explainer(X_all)\n",
    "\n",
    "        # 绘制 SHAP 总结图\n",
    "        shap.summary_plot(shap_values, X_all, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "        plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\SHAP_Summary_{name}_AllData.png')\n",
    "        plt.close()\n",
    "\n",
    "        # 绘制 SHAP 散点图\n",
    "        shap.summary_plot(shap_values, X_all, feature_names=feature_names, plot_type=\"dot\", show=False)\n",
    "        plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\SHAP_Scatter_{name}_AllData.png')\n",
    "        plt.close()\n",
    "\n",
    "print(\"SHAP explanations have been generated and saved for each model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 加载 SimHei 字体\n",
    "font_path = r\"C:\\Windows\\Fonts\\SimHei.ttf\"  # 请根据你的系统调整路径\n",
    "prop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# 全局设置 Matplotlib 使用 SimHei 字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 全局设置字体为 SimHei\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "\n",
    "# 确保特征名称正确\n",
    "feature_names = all_data.columns[1:12]  # 第2到12列为特征名称\n",
    "\n",
    "# 对每个模型进行 SHAP 解释\n",
    "for name, model in models.items():\n",
    "    print(f\"Generating SHAP explanations for model: {name}\")\n",
    "\n",
    "    # 使用 TreeExplainer 对树模型（XGBoost、LGBM、CatBoost）进行解释\n",
    "    if name in [\"XGBoost\", \"LGBM\", \"CatBoost\"]:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_all)\n",
    "\n",
    "        # 绘制 SHAP 总结图（柱状图）\n",
    "        shap.summary_plot(shap_values, X_all, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "        plt.title(f\"SHAP 总结图 - {name}\", fontproperties=prop)\n",
    "        plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\SHAP_Summary_{name}_AllData.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # 绘制 SHAP 散点图（按特征显示的散点图）\n",
    "        if isinstance(shap_values, list):  # 检查是否有多个类别\n",
    "            for i in range(len(shap_values)):\n",
    "                shap.summary_plot(shap_values[i], X_all, feature_names=feature_names, plot_type=\"dot\", show=False)\n",
    "                plt.title(f\"SHAP 散点图 - {name} - 类别 {i}\", fontproperties=prop)\n",
    "                plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\SHAP_Scatter_{name}_AllData_class_{i}.png', bbox_inches='tight')\n",
    "                plt.close()\n",
    "        else:\n",
    "            shap.summary_plot(shap_values, X_all, feature_names=feature_names, plot_type=\"dot\", show=False)\n",
    "            plt.title(f\"SHAP 散点图 - {name}\", fontproperties=prop)\n",
    "            plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\SHAP_Scatter_{name}_AllData.png', bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "    # 使用通用的 SHAP Explainer 进行解释 (NGBoost)\n",
    "    elif name == \"NGBoost\":\n",
    "        explainer = shap.Explainer(model.predict, X_all)\n",
    "        shap_values = explainer(X_all)\n",
    "\n",
    "        # 绘制 SHAP 总结图\n",
    "        shap.summary_plot(shap_values, X_all, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "        plt.title(f\"SHAP 总结图 - {name}\", fontproperties=prop)\n",
    "        plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\SHAP_Summary_{name}_AllData.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        # 绘制 SHAP 散点图\n",
    "        shap.summary_plot(shap_values, X_all, feature_names=feature_names, plot_type=\"dot\", show=False)\n",
    "        plt.title(f\"SHAP 散点图 - {name}\", fontproperties=prop)\n",
    "        plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\SHAP_Scatter_{name}_AllData.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "print(\"SHAP explanations have been generated and saved for each model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保特征名称正确   这个是两种因素之间的依赖图\n",
    "if \"CatBoost\" in models:\n",
    "    print(\"Generating custom SHAP scatter plots for CatBoost model...\")\n",
    "\n",
    "    # 提取 CatBoost 模型和 SHAP 解释器\n",
    "    model = models[\"CatBoost\"]\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_all)\n",
    "\n",
    "    # 如果 shap_values 是列表（分类任务），选择第一个类别的 SHAP 值\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[0]\n",
    "\n",
    "    # 确保 feature_names 是一个列表\n",
    "    feature_names = list(feature_names)\n",
    "\n",
    "    # 确保 X_all 是 Pandas 数据框\n",
    "    import pandas as pd\n",
    "    if not isinstance(X_all, pd.DataFrame):\n",
    "        X_all = pd.DataFrame(X_all, columns=feature_names)\n",
    "\n",
    "    # 遍历每个特征，绘制单特征 SHAP 散点图\n",
    "    for feature in feature_names:\n",
    "        print(f\"Plotting SHAP scatter plot for feature: {feature}\")\n",
    "\n",
    "        # 获取当前特征值和对应的 SHAP 值\n",
    "        feature_values = X_all[feature].values\n",
    "        feature_shap_values = shap_values[:, feature_names.index(feature)]\n",
    "\n",
    "        # 绘制单特征的散点图\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.scatter(feature_values, feature_shap_values, alpha=0.7, s=10, c='blue')\n",
    "        plt.axhline(y=0, color='gray', linestyle='--', linewidth=0.8)\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(\"SHAP value\")\n",
    "        plt.title(f\"SHAP Scatter Plot for {feature}\")\n",
    "        plt.grid(alpha=0.3)\n",
    "\n",
    "        # 保存图像\n",
    "        plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\SHAP_Custom_CatBoost_{feature}.png')\n",
    "        plt.close()\n",
    "\n",
    "    print(\"Custom SHAP scatter plots for CatBoost model have been generated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保特征名称正确   单因素的依赖图 英文论文的\n",
    "if \"CatBoost\" in models:\n",
    "    print(\"Generating custom SHAP scatter plots for CatBoost model...\")\n",
    "\n",
    "    # 提取 CatBoost 模型和 SHAP 解释器\n",
    "    model = models[\"CatBoost\"]\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_all)\n",
    "\n",
    "    # 如果 shap_values 是列表（分类任务），选择第一个类别的 SHAP 值\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[0]\n",
    "\n",
    "    # 确保 feature_names 是一个列表\n",
    "    feature_names = list(feature_names)\n",
    "\n",
    "    # 遍历每个特征，绘制单特征 SHAP 散点图\n",
    "    for feature in feature_names:\n",
    "        print(f\"Plotting SHAP scatter plot for feature: {feature}\")\n",
    "\n",
    "        # 提取原始特征值（确保原始数据与标准化数据对齐）\n",
    "        # original_data 应该是未处理过的原始数据\n",
    "        original_data = pd.read_excel(r'D:\\Users\\刘洋\\Desktop\\original_data - 副本.xlsx')  # 替换为原始数据文件路径\n",
    "\n",
    "       \n",
    "\n",
    "        original_data = original_data.reset_index(drop=True)\n",
    "        X_all = X_all.reset_index(drop=True)\n",
    "        feature_values = original_data[feature].values  # 使用原始数据的特征值\n",
    "\n",
    "        # 提取对应的 SHAP 值\n",
    "        feature_shap_values = shap_values[:, feature_names.index(feature)]\n",
    "\n",
    "        # 绘制单特征的散点图\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(feature_values, feature_shap_values, alpha=0.7, s=10, c='blue')\n",
    "        plt.axhline(y=0, color='gray', linestyle='--', linewidth=0.8)\n",
    "\n",
    "        # 增大横纵坐标的标度值字体大小\n",
    "        plt.xticks(fontsize=12)  # 设置横坐标标度值字体大小\n",
    "        plt.yticks(fontsize=12)  # 设置纵坐标标度值字体大小\n",
    "\n",
    "\n",
    "        plt.xlabel(f\"{feature} (Original Feature Values)\", fontsize=12)  # 横坐标为原始特征值\n",
    "        plt.ylabel(\"SHAP value \", fontsize=12)\n",
    "        #plt.title(f\"SHAP Scatter Plot for {feature}\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        # 去除多余空白\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 保存图像\n",
    "        plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\{feature}.png')\n",
    "        plt.close()\n",
    "\n",
    "    print(\"Custom SHAP scatter plots for CatBoost model have been generated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保特征名称正确 单因素的依赖图 专利\n",
    "if \"CatBoost\" in models:\n",
    "    print(\"Generating custom SHAP scatter plots for CatBoost model...\")\n",
    "\n",
    "    # 提取 CatBoost 模型和 SHAP 解释器\n",
    "    model = models[\"CatBoost\"]\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_all)\n",
    "\n",
    "    # 如果 shap_values 是列表（分类任务），选择第一个类别的 SHAP 值\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[0]\n",
    "\n",
    "    # 确保 feature_names 是一个列表\n",
    "    feature_names = list(feature_names)\n",
    "\n",
    "    # 将 X_all 转换为 DataFrame 以便使用 reset_index()\n",
    "    X_all_df = pd.DataFrame(X_all, columns=feature_names)\n",
    "    X_all_df = X_all_df.reset_index(drop=True)\n",
    "\n",
    "    # 遍历每个特征，绘制单特征 SHAP 散点图\n",
    "    for feature in feature_names:\n",
    "        print(f\"Plotting SHAP scatter plot for feature: {feature}\")\n",
    "\n",
    "        # 提取原始特征值（确保原始数据与标准化数据对齐）\n",
    "        # original_data 应该是未处理过的原始数据\n",
    "        original_data = pd.read_excel(r'D:\\Users\\刘洋\\Desktop\\original_data - 副本.xlsx')  # 替换为原始数据文件路径\n",
    "\n",
    "        original_data = original_data.reset_index(drop=True)\n",
    "        feature_values = original_data[feature].values  # 使用原始数据的特征值\n",
    "\n",
    "        # 提取对应的 SHAP 值\n",
    "        feature_shap_values = shap_values[:, feature_names.index(feature)]\n",
    "\n",
    "        # 绘制单特征的散点图\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(feature_values, feature_shap_values, alpha=0.7, s=10, c='blue')\n",
    "        plt.axhline(y=0, color='gray', linestyle='--', linewidth=0.8)\n",
    "\n",
    "        # 增大横纵坐标的标度值字体大小\n",
    "        plt.xticks(fontsize=16)  # 设置横坐标标度值字体大小\n",
    "        plt.yticks(fontsize=16)  # 设置纵坐标标度值字体大小\n",
    "\n",
    "        plt.xlabel(f\"{feature} \", fontsize=16, family='SimHei')  # 横坐标为原始特征值\n",
    "        plt.ylabel(\"SHAP 值 \", fontsize=16, family='SimHei')\n",
    "        # plt.title(f\"SHAP Scatter Plot for {feature}\")\n",
    "        plt.grid(alpha=0.3)\n",
    "\n",
    "        # 去除多余空白\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 保存图像\n",
    "        plt.savefig(fr'D:\\Users\\刘洋\\Desktop\\{feature}.png')\n",
    "        plt.close()\n",
    "\n",
    "    print(\"Custom SHAP scatter plots for CatBoost model have been generated and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
